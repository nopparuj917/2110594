{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQ8FRFIYMc5X"
      },
      "source": [
        "# HOMEWORK 6: TEXT CLASSIFICATION\n",
        "In this homework, you will create models to classify texts from TRUE call-center. There are two classification tasks:\n",
        "1. Action Classification: Identify which action the customer would like to take (e.g. enquire, report, cancle)\n",
        "2. Object Classification: Identify which object the customer is referring to (e.g. payment, truemoney, internet, roaming) \n",
        "\n",
        "In this homework, you are asked to do the following tasks:\n",
        "1. Data Cleaning\n",
        "2. Preprocessing data for pytorch\n",
        "3. Build and evaluate a model for \"action\" classification\n",
        "4. Build and evaluate a model for \"object\" classification\n",
        "5. Build and evaluate a multi-task model that does both \"action\" and \"object\" classifications in one-go \n",
        "\n",
        "\n",
        "Note: we have removed phone numbers from the dataset for privacy purposes. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHqkFSyaNvOt"
      },
      "source": [
        "# !wget --no-check-certificate https://www.dropbox.com/s/37u83g55p19kvrl/clean-phone-data-for-students.csv\n",
        "# !pip install pythainlp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YprqbOPMc5a"
      },
      "source": [
        "## Import Libs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heICP79cMc5e"
      },
      "source": [
        "%matplotlib inline\n",
        "import time\n",
        "import pandas\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import pandas as pd \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from IPython.display import display\n",
        "from pythainlp.tokenize import word_tokenize\n",
        "from collections import defaultdict\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from pythainlp.tokenize import word_tokenize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data.dataset import random_split\n",
        "from torchtext.data.functional import to_map_style_dataset"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPaUf4PLMc5k"
      },
      "source": [
        "## Loading data\n",
        "First, we load the data from disk into a Dataframe.\n",
        "\n",
        "A Dataframe is essentially a table, or 2D-array/Matrix with a name for each column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhZ2eBAWMc5l"
      },
      "source": [
        "# data_df = pd.read_csv('clean-phone-data-for-students.csv')"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGd8BNvMMc5y"
      },
      "source": [
        "## Data cleaning\n",
        "\n",
        "We call the DataFrame.describe() again.\n",
        "Notice that there are 33 unique labels/classes for object and 10 unique labels for action that the model will try to predict.\n",
        "But there are unwanted duplications e.g. Idd,idd,lotalty_card,Lotalty_card\n",
        "\n",
        "Also note that, there are 13389 unqiue sentence utterances from 16175 utterances. You have to clean that too!\n",
        "\n",
        "## #TODO 1: \n",
        "You will have to remove unwanted label duplications as well as duplications in text inputs. \n",
        "Also, you will have to trim out unwanted whitespaces from the text inputs. \n",
        "This shouldn't be too hard, as you have already seen it in the demo.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0bGLblVMc5z"
      },
      "source": [
        "# display(data_df.describe())\n",
        "# display(data_df.Object.unique())\n",
        "# display(data_df.Action.unique())"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19onNNUZMc54"
      },
      "source": [
        "# TODO1: Data cleaning\n",
        "data_df = pd.read_csv('clean-phone-data-for-students.csv')\n",
        "\n",
        "data_df_obj = data_df[['Sentence Utterance', 'Object']]\n",
        "data_df_obj.columns = ['input', 'raw_label']\n",
        "data_df_obj['clean_label'] = data_df_obj['raw_label'].str.lower().copy()\n",
        "data_df_obj.drop('raw_label', axis=1, inplace=True)\n",
        "data_df_obj = data_df_obj.drop_duplicates('input', keep='first')\n",
        "data_obj = data_df_obj.to_numpy()\n",
        "\n",
        "unique_label = data_df_obj.clean_label.unique()\n",
        "label_2_num_map = dict(zip(unique_label, range(len(unique_label))))\n",
        "num_2_label_map = dict(zip(range(len(unique_label)), unique_label))\n",
        "data_obj[:, 1] = np.vectorize(label_2_num_map.get)(data_obj[:, 1])\n",
        "\n",
        "data_df_act = data_df[['Sentence Utterance', 'Action']]\n",
        "data_df_act.columns = ['input', 'raw_label']\n",
        "data_df_act['clean_label'] = data_df_act['raw_label'].str.lower().copy()\n",
        "data_df_act.drop('raw_label', axis=1, inplace=True)\n",
        "data_df_act = data_df_act.drop_duplicates('input', keep='first')\n",
        "data_act = data_df_act.to_numpy()\n",
        "\n",
        "unique_label = data_df_act.clean_label.unique()\n",
        "label_2_num_map = dict(zip(unique_label, range(len(unique_label))))\n",
        "num_2_label_map = dict(zip(range(len(unique_label)), unique_label))\n",
        "data_act[:, 1] = np.vectorize(label_2_num_map.get)(data_act[:, 1])\n",
        "\n",
        "def strip_str(string):\n",
        "    return string.strip()\n",
        "\n",
        "data_obj[:, 0] = np.vectorize(strip_str)(data_obj[:, 0])\n",
        "data_act[:, 0] = np.vectorize(strip_str)(data_act[:, 0])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TODO2 : Assign index to word and labels in each sentences. \n",
        "\n",
        "Note that please use **word_tokenize** (https://pythainlp.github.io/docs/2.0/api/tokenize.html) as a function to tokenize each sentences."
      ],
      "metadata": {
        "id": "Oo1YByXlzr67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO2: assign index to each words and labels in sentence.\n",
        "tokenized_obj, labels_obj = zip(*[(word_tokenize(sentence, engine=\"newmm\"), label) for sentence, label in data_obj])\n",
        "tokenized_act, labels_act = zip(*[(word_tokenize(sentence, engine=\"newmm\"), label) for sentence, label in data_act])\n",
        "vocab = build_vocab_from_iterator(tokenized_obj, specials=[\"<unk>\"])\n",
        "vocab.set_default_index(vocab[\"<unk>\"])\n",
        "embedded_obj = [[labels_obj[i], vocab(tokens)] for i, tokens in enumerate(tokenized_obj)]\n",
        "embedded_act = [[labels_act[i], vocab(tokens)] for i, tokens in enumerate(tokenized_act)]\n",
        "embedded_act_obj = [[labels_act[i],labels_obj[i], vocab(tokens)] for i, tokens in enumerate(tokenized_act)]\n",
        "# embedded_act_obj = []\n",
        "# label_act_obj = dict()\n",
        "# for i,tokens in enumerate(tokenized_act):\n",
        "#   if (labels_obj[i],labels_act[i]) not in label_act_obj:\n",
        "#     label_act_obj[(labels_obj[i],labels_act[i])] = len(label_act_obj)\n",
        "#   embedded_act_obj.append([label_act_obj[(labels_obj[i],labels_act[i])],vocab(tokens)]) "
      ],
      "metadata": {
        "id": "crwlkeMVyHh_"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BZZYPuIMc59"
      },
      "source": [
        "## TODO 2,3: Preprocessing data for pytorch\n",
        "You will be using pytorch in this assignment. Please show us how you prepare your dataloader for pytorch.\n",
        "Don't forget to split data into train, valdation, and test sets (normally the ratio will be 80:10:10 , respectively)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## TODO 3: Split the data\n",
        "\n",
        "We recommend to use train_test_spilt from scikit-learn to split the data into train, validation, test set. \n",
        "\n",
        "In addition, it should split the data that distribution of the labels in train , validation, test set are similar. There is **stratify** variable handling this issue. \n",
        "\n",
        "In this case, you can choose whatever you want either \"**Action**\" or \"**Object**\" ;). \n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n"
      ],
      "metadata": {
        "id": "R7Uf8UwWJkhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO3: split data into train, validation, test  \n",
        "train_data_act, test_data_act = train_test_split(embedded_act, test_size=0.2, shuffle=False)\n",
        "train_data_act, val_data_act = train_test_split(train_data_act, test_size=0.1, shuffle=False)\n",
        "\n",
        "train_data_obj, test_data_obj = train_test_split(embedded_obj, test_size=0.2, shuffle=False)\n",
        "train_data_obj, val_data_obj = train_test_split(train_data_obj, test_size=0.1, shuffle=False)\n",
        "\n",
        "train_data_act_obj,test_data_act_obj = train_test_split(embedded_act_obj,test_size = 0.2, shuffle=False)\n",
        "train_data_act_obj,val_data_act_obj = train_test_split(train_data_act_obj,test_size = 0.1, shuffle=False)"
      ],
      "metadata": {
        "id": "k2NPVYj5JU1H"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TODO 4: Build a model for classifying these texts.\n"
      ],
      "metadata": {
        "id": "qKeikxDy5Ahs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TextClassificationModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_class):\n",
        "        super(TextClassificationModel, self).__init__()\n",
        "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
        "        self.fc = nn.Linear(embed_dim, num_class)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.5\n",
        "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.bias.data.zero_()\n",
        "\n",
        "    def forward(self, text, offsets):\n",
        "        embedded = self.embedding(text, offsets)\n",
        "        return self.fc(embedded)"
      ],
      "metadata": {
        "id": "ZFbWhiMF-7oL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_batch(batch):\n",
        "    label_list, text_list, offsets = [], [], [0]\n",
        "    for (_label, _text) in batch:\n",
        "         label_list.append(_label)\n",
        "         processed_text = torch.tensor(_text, dtype=torch.int64)\n",
        "         text_list.append(processed_text)\n",
        "         offsets.append(processed_text.size(0))\n",
        "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
        "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "    text_list = torch.cat(text_list)\n",
        "    return label_list.to(device), text_list.to(device), offsets.to(device)\n",
        "\n",
        "def train(dataloader):\n",
        "    model.train()\n",
        "    total_acc, total_count = 0, 0\n",
        "    log_interval = 500\n",
        "    start_time = time.time()\n",
        "\n",
        "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        predicted_label = model(text, offsets)\n",
        "        loss = criterion(predicted_label, label)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
        "        optimizer.step()\n",
        "        total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
        "        total_count += label.size(0)\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
        "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
        "                                              total_acc/total_count))\n",
        "            total_acc, total_count = 0, 0\n",
        "            start_time = time.time()\n",
        "\n",
        "def evaluate(dataloader):\n",
        "    model.eval()\n",
        "    total_acc, total_count = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
        "            predicted_label = model(text, offsets)\n",
        "            loss = criterion(predicted_label, label)\n",
        "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
        "            total_count += label.size(0)\n",
        "    return total_acc/total_count"
      ],
      "metadata": {
        "id": "WrjciLUXBfc6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tXZiLZ4Mc6E"
      },
      "source": [
        "## #TODO 3: Build and evaluate a model for \"action\" classification\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=8\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "num_class_act = len(set([label for label in labels_act]))\n",
        "num_class_obj = len(set([label for label in labels_obj]))\n",
        "emsize = 64"
      ],
      "metadata": {
        "id": "fzXiyzXugeCS"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TextClassificationModel(len(vocab), emsize, num_class_act).to(device)\n",
        "train_dataloader = DataLoader(train_data_act, batch_size=batch_size, shuffle=False,collate_fn=collate_batch)\n",
        "val_dataloader = DataLoader(val_data_act, batch_size=batch_size, shuffle=False,collate_fn=collate_batch)\n",
        "test_dataloader = DataLoader(test_data_act, batch_size=batch_size, shuffle=False,collate_fn=collate_batch)\n",
        "# Hyperparameters\n",
        "EPOCHS = 10 # epoch\n",
        "LR = 5  # learning rate\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
        "total_accu = None\n",
        "num_train = int(len(data_act) * 0.95)\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    train(train_dataloader)\n",
        "    accu_val = evaluate(val_dataloader)\n",
        "    if total_accu is not None and total_accu > accu_val:\n",
        "      scheduler.step()\n",
        "    else:\n",
        "       total_accu = accu_val\n",
        "    print('-' * 59)\n",
        "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
        "          'valid accuracy {:8.3f} '.format(epoch,\n",
        "                                           time.time() - epoch_start_time,\n",
        "                                           accu_val))\n",
        "    print('-' * 59)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RR_0L8ZVhp7T",
        "outputId": "498cabaa-b60b-4532-bbfa-80e33414c3c6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   500/ 1205 batches | accuracy    0.757\n",
            "| epoch   1 |  1000/ 1205 batches | accuracy    0.804\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   1 | time:  5.29s | valid accuracy    0.864 \n",
            "-----------------------------------------------------------\n",
            "| epoch   2 |   500/ 1205 batches | accuracy    0.821\n",
            "| epoch   2 |  1000/ 1205 batches | accuracy    0.826\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   2 | time:  2.35s | valid accuracy    0.869 \n",
            "-----------------------------------------------------------\n",
            "| epoch   3 |   500/ 1205 batches | accuracy    0.836\n",
            "| epoch   3 |  1000/ 1205 batches | accuracy    0.839\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   3 | time:  2.44s | valid accuracy    0.874 \n",
            "-----------------------------------------------------------\n",
            "| epoch   4 |   500/ 1205 batches | accuracy    0.848\n",
            "| epoch   4 |  1000/ 1205 batches | accuracy    0.848\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   4 | time:  2.17s | valid accuracy    0.869 \n",
            "-----------------------------------------------------------\n",
            "| epoch   5 |   500/ 1205 batches | accuracy    0.863\n",
            "| epoch   5 |  1000/ 1205 batches | accuracy    0.879\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   5 | time:  1.96s | valid accuracy    0.888 \n",
            "-----------------------------------------------------------\n",
            "| epoch   6 |   500/ 1205 batches | accuracy    0.873\n",
            "| epoch   6 |  1000/ 1205 batches | accuracy    0.884\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   6 | time:  1.97s | valid accuracy    0.887 \n",
            "-----------------------------------------------------------\n",
            "| epoch   7 |   500/ 1205 batches | accuracy    0.879\n",
            "| epoch   7 |  1000/ 1205 batches | accuracy    0.891\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   7 | time:  1.95s | valid accuracy    0.885 \n",
            "-----------------------------------------------------------\n",
            "| epoch   8 |   500/ 1205 batches | accuracy    0.880\n",
            "| epoch   8 |  1000/ 1205 batches | accuracy    0.893\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   8 | time:  2.00s | valid accuracy    0.886 \n",
            "-----------------------------------------------------------\n",
            "| epoch   9 |   500/ 1205 batches | accuracy    0.879\n",
            "| epoch   9 |  1000/ 1205 batches | accuracy    0.894\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   9 | time:  2.21s | valid accuracy    0.886 \n",
            "-----------------------------------------------------------\n",
            "| epoch  10 |   500/ 1205 batches | accuracy    0.879\n",
            "| epoch  10 |  1000/ 1205 batches | accuracy    0.894\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  10 | time:  2.13s | valid accuracy    0.885 \n",
            "-----------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## TODO 3.5: evalaute on test set  \n",
        "evaluate(test_dataloader)"
      ],
      "metadata": {
        "id": "I4eM-ZeySJVb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4480fc38-9266-44f2-b4b1-a76507760500"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8450336071695295"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLRUK0Q8Mc6J"
      },
      "source": [
        "## #TODO 4: Build and evaluate a model for \"object\" classification\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9evsrIiKMc6K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c016754-b7b2-45dc-8c84-a719f0c2fec2"
      },
      "source": [
        "model = TextClassificationModel(len(vocab), emsize, num_class_act).to(device)\n",
        "train_dataloader = DataLoader(train_data_act, batch_size=batch_size, shuffle=False,collate_fn=collate_batch)\n",
        "val_dataloader = DataLoader(val_data_act, batch_size=batch_size, shuffle=False,collate_fn=collate_batch)\n",
        "test_dataloader = DataLoader(test_data_act, batch_size=batch_size, shuffle=False,collate_fn=collate_batch)\n",
        "# Hyperparameters\n",
        "EPOCHS = 10 # epoch\n",
        "LR = 5  # learning rate\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
        "total_accu = None\n",
        "num_train = int(len(data_act) * 0.95)\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    train(train_dataloader)\n",
        "    accu_val = evaluate(val_dataloader)\n",
        "    if total_accu is not None and total_accu > accu_val:\n",
        "      scheduler.step()\n",
        "    else:\n",
        "       total_accu = accu_val\n",
        "    print('-' * 59)\n",
        "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
        "          'valid accuracy {:8.3f} '.format(epoch,\n",
        "                                           time.time() - epoch_start_time,\n",
        "                                           accu_val))\n",
        "    print('-' * 59)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   500/ 1205 batches | accuracy    0.759\n",
            "| epoch   1 |  1000/ 1205 batches | accuracy    0.805\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   1 | time:  1.95s | valid accuracy    0.865 \n",
            "-----------------------------------------------------------\n",
            "| epoch   2 |   500/ 1205 batches | accuracy    0.825\n",
            "| epoch   2 |  1000/ 1205 batches | accuracy    0.824\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   2 | time:  1.97s | valid accuracy    0.872 \n",
            "-----------------------------------------------------------\n",
            "| epoch   3 |   500/ 1205 batches | accuracy    0.838\n",
            "| epoch   3 |  1000/ 1205 batches | accuracy    0.840\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   3 | time:  2.69s | valid accuracy    0.873 \n",
            "-----------------------------------------------------------\n",
            "| epoch   4 |   500/ 1205 batches | accuracy    0.850\n",
            "| epoch   4 |  1000/ 1205 batches | accuracy    0.850\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   4 | time:  2.27s | valid accuracy    0.877 \n",
            "-----------------------------------------------------------\n",
            "| epoch   5 |   500/ 1205 batches | accuracy    0.858\n",
            "| epoch   5 |  1000/ 1205 batches | accuracy    0.860\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   5 | time:  1.95s | valid accuracy    0.873 \n",
            "-----------------------------------------------------------\n",
            "| epoch   6 |   500/ 1205 batches | accuracy    0.869\n",
            "| epoch   6 |  1000/ 1205 batches | accuracy    0.887\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   6 | time:  1.91s | valid accuracy    0.883 \n",
            "-----------------------------------------------------------\n",
            "| epoch   7 |   500/ 1205 batches | accuracy    0.882\n",
            "| epoch   7 |  1000/ 1205 batches | accuracy    0.891\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   7 | time:  1.92s | valid accuracy    0.889 \n",
            "-----------------------------------------------------------\n",
            "| epoch   8 |   500/ 1205 batches | accuracy    0.885\n",
            "| epoch   8 |  1000/ 1205 batches | accuracy    0.895\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   8 | time:  1.93s | valid accuracy    0.884 \n",
            "-----------------------------------------------------------\n",
            "| epoch   9 |   500/ 1205 batches | accuracy    0.890\n",
            "| epoch   9 |  1000/ 1205 batches | accuracy    0.901\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   9 | time:  2.08s | valid accuracy    0.886 \n",
            "-----------------------------------------------------------\n",
            "| epoch  10 |   500/ 1205 batches | accuracy    0.891\n",
            "| epoch  10 |  1000/ 1205 batches | accuracy    0.903\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  10 | time:  2.25s | valid accuracy    0.886 \n",
            "-----------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## TODO 4.5: evalaute on test set  \n",
        "evaluate(test_dataloader)"
      ],
      "metadata": {
        "id": "VGwjOiD8TQYh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "599ce727-ffa8-4922-8b99-17418865a1f8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8454070201643017"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsAxmXfGMc6N"
      },
      "source": [
        "## #TODO 5: Build and evaluate a multi-task model that does both \"action\" and \"object\" classifications in one-go \n",
        "\n",
        "The model will have 2 separate output layers one for action classification task and another for object classification task. \n",
        "\n",
        "This is a rough sketch of what your model might look like:\n",
        "![image](https://raw.githubusercontent.com/ekapolc/nlp_course/master/HW5/multitask_sketch.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZX6wx49Mc6P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32a35b6c-568c-479b-a470-280f1511f47a"
      },
      "source": [
        "model = TextClassificationModel(len(vocab), emsize, num_class_act_obj).to(device)\n",
        "train_dataloader = DataLoader(train_data_act_obj, batch_size=batch_size, shuffle=False,collate_fn=collate_batch)\n",
        "val_dataloader = DataLoader(val_data_act_obj, batch_size=batch_size, shuffle=False,collate_fn=collate_batch)\n",
        "test_dataloader = DataLoader(test_data_act_obj, batch_size=batch_size, shuffle=False,collate_fn=collate_batch)\n",
        "# Hyperparameters\n",
        "EPOCHS = 10 # epoch\n",
        "LR = 5  # learning rate\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
        "total_accu = None\n",
        "num_train = int(len(data_act) * 0.95)\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    train(train_dataloader)\n",
        "    accu_val = evaluate(val_dataloader)\n",
        "    if total_accu is not None and total_accu > accu_val:\n",
        "      scheduler.step()\n",
        "    else:\n",
        "       total_accu = accu_val\n",
        "    print('-' * 59)\n",
        "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
        "          'valid accuracy {:8.3f} '.format(epoch,\n",
        "                                           time.time() - epoch_start_time,\n",
        "                                           accu_val))\n",
        "    print('-' * 59)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   500/ 1205 batches | accuracy    0.469\n",
            "| epoch   1 |  1000/ 1205 batches | accuracy    0.616\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   1 | time:  2.15s | valid accuracy    0.636 \n",
            "-----------------------------------------------------------\n",
            "| epoch   2 |   500/ 1205 batches | accuracy    0.643\n",
            "| epoch   2 |  1000/ 1205 batches | accuracy    0.691\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   2 | time:  2.20s | valid accuracy    0.632 \n",
            "-----------------------------------------------------------\n",
            "| epoch   3 |   500/ 1205 batches | accuracy    0.729\n",
            "| epoch   3 |  1000/ 1205 batches | accuracy    0.773\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   3 | time:  1.97s | valid accuracy    0.663 \n",
            "-----------------------------------------------------------\n",
            "| epoch   4 |   500/ 1205 batches | accuracy    0.751\n",
            "| epoch   4 |  1000/ 1205 batches | accuracy    0.783\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   4 | time:  1.96s | valid accuracy    0.668 \n",
            "-----------------------------------------------------------\n",
            "| epoch   5 |   500/ 1205 batches | accuracy    0.759\n",
            "| epoch   5 |  1000/ 1205 batches | accuracy    0.790\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   5 | time:  1.95s | valid accuracy    0.673 \n",
            "-----------------------------------------------------------\n",
            "| epoch   6 |   500/ 1205 batches | accuracy    0.769\n",
            "| epoch   6 |  1000/ 1205 batches | accuracy    0.795\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   6 | time:  1.92s | valid accuracy    0.671 \n",
            "-----------------------------------------------------------\n",
            "| epoch   7 |   500/ 1205 batches | accuracy    0.770\n",
            "| epoch   7 |  1000/ 1205 batches | accuracy    0.806\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   7 | time:  2.10s | valid accuracy    0.679 \n",
            "-----------------------------------------------------------\n",
            "| epoch   8 |   500/ 1205 batches | accuracy    0.775\n",
            "| epoch   8 |  1000/ 1205 batches | accuracy    0.808\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   8 | time:  2.20s | valid accuracy    0.678 \n",
            "-----------------------------------------------------------\n",
            "| epoch   9 |   500/ 1205 batches | accuracy    0.775\n",
            "| epoch   9 |  1000/ 1205 batches | accuracy    0.810\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   9 | time:  1.97s | valid accuracy    0.679 \n",
            "-----------------------------------------------------------\n",
            "| epoch  10 |   500/ 1205 batches | accuracy    0.775\n",
            "| epoch  10 |  1000/ 1205 batches | accuracy    0.809\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  10 | time:  1.96s | valid accuracy    0.679 \n",
            "-----------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_class_act,num_class_obj):\n",
        "        super(Model, self).__init__()\n",
        "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
        "        self.fc_act = nn.Linear(embed_dim, num_class_act)\n",
        "        self.fc_obj = nn.Linear(embed_dim, num_class_obj)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.5\n",
        "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc_act.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc_act.bias.data.zero_()\n",
        "        self.fc_obj.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc_obj.bias.data.zero_()\n",
        "\n",
        "    def forward(self, text, offsets):\n",
        "        embedded = self.embedding(text, offsets)\n",
        "        return self.fc_act(embedded), self.fc_obj(embedded)"
      ],
      "metadata": {
        "id": "aujjRRRHTgzt"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_batch_mul(batch):\n",
        "    label_list_act,label_list_obj, text_list, offsets = [], [], [], [0]\n",
        "    for (_label_act,_label_obj, _text) in batch:\n",
        "         label_list_act.append(_label_act)\n",
        "         label_list_obj.append(_label_obj)\n",
        "         processed_text = torch.tensor(_text, dtype=torch.int64)\n",
        "         text_list.append(processed_text)\n",
        "         offsets.append(processed_text.size(0))\n",
        "    label_list_act = torch.tensor(label_list_act, dtype=torch.int64)\n",
        "    label_list_obj = torch.tensor(label_list_obj, dtype=torch.int64)\n",
        "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "    text_list = torch.cat(text_list)\n",
        "    return label_list_act.to(device),label_list_obj.to(device), text_list.to(device), offsets.to(device)\n",
        "\n",
        "def train_mul(dataloader):\n",
        "    model_mul.train()\n",
        "    total_acc_act, total_count_act,total_acc_obj,total_count_obj = 0, 0,0,0\n",
        "    log_interval = 500\n",
        "    start_time = time.time()\n",
        "    for idx, (label_act,label_obj, text, offsets) in enumerate(dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        predicted_label_act,predicted_label_obj = model_mul(text, offsets)\n",
        "        loss = criterion(predicted_label_act, label_act) + criterion(predicted_label_obj, label_obj)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model_mul.parameters(), 0.1)\n",
        "        optimizer.step()\n",
        "        total_acc_act += (predicted_label_act.argmax(1) == label_act).sum().item()\n",
        "        total_acc_obj += (predicted_label_obj.argmax(1) == label_obj).sum().item()\n",
        "        total_count_act += label_act.size(0)\n",
        "        total_count_obj += label_obj.size(0)\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
        "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
        "                                              total_acc_act/total_count_act))\n",
        "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
        "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
        "                                              total_acc_obj/total_count_obj))\n",
        "            total_acc_act, total_count_act,total_acc_obj,total_count_obj = 0, 0,0,0\n",
        "            start_time = time.time()\n",
        "\n",
        "def evaluate_mul(dataloader):\n",
        "    model_mul.eval()\n",
        "    total_acc_act, total_count_act,total_acc_obj,total_count_obj = 0, 0,0,0\n",
        "    with torch.no_grad():\n",
        "        for idx, (label_act,label_obj, text, offsets) in enumerate(dataloader):\n",
        "            predicted_label_act,predicted_label_obj = model_mul(text, offsets)\n",
        "            loss = criterion(predicted_label_act, label_act) + criterion(predicted_label_obj, label_obj)\n",
        "            total_acc_act += (predicted_label_act.argmax(1) == label_act).sum().item()\n",
        "            total_acc_obj += (predicted_label_obj.argmax(1) == label_obj).sum().item()\n",
        "            total_count_act += label_act.size(0)\n",
        "            total_count_obj += label_obj.size(0)\n",
        "    return total_acc_act/total_count_act, total_acc_obj/total_count_obj"
      ],
      "metadata": {
        "id": "dsecsV2mCOFg"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_mul = Model(len(vocab), emsize, num_class_act,num_class_obj).to(device)\n",
        "train_dataloader = DataLoader(train_data_act_obj, batch_size=batch_size, shuffle=False,collate_fn=collate_batch_mul)\n",
        "val_dataloader = DataLoader(val_data_act_obj, batch_size=batch_size, shuffle=False,collate_fn=collate_batch_mul)\n",
        "test_dataloader = DataLoader(test_data_act_obj, batch_size=batch_size, shuffle=False,collate_fn=collate_batch_mul)\n",
        "# Hyperparameters\n",
        "EPOCHS = 10 # epoch\n",
        "LR = 5  # learning rate\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model_mul.parameters(), lr=LR)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
        "total_accu_act = None\n",
        "total_accu_obj = None\n",
        "num_train = int(len(data_act) * 0.95)\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    train_mul(train_dataloader)\n",
        "    accu_val_act, accu_val_obj= evaluate_mul(val_dataloader)\n",
        "    if total_accu_act is not None and total_accu_obj is not None and total_accu_act > accu_val_act and total_accu_obj > accu_val_obj:\n",
        "      scheduler.step()\n",
        "    else:\n",
        "       total_accu_act = accu_val_act\n",
        "       total_accu_obj = accu_val_obj\n",
        "    print('-' * 59)\n",
        "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
        "          'valid accuracy {:8.3f}, {:8.3f}'.format(epoch,\n",
        "                                           time.time() - epoch_start_time,\n",
        "                                           accu_val_act,accu_val_obj))\n",
        "    print('-' * 59)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8s8y0atQDPta",
        "outputId": "ff561436-fae5-458a-bd25-2f63eed110cf"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   500/ 1205 batches | accuracy    0.759\n",
            "| epoch   1 |   500/ 1205 batches | accuracy    0.498\n",
            "| epoch   1 |  1000/ 1205 batches | accuracy    0.808\n",
            "| epoch   1 |  1000/ 1205 batches | accuracy    0.628\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   1 | time:  2.40s | valid accuracy    0.860,    0.617\n",
            "-----------------------------------------------------------\n",
            "| epoch   2 |   500/ 1205 batches | accuracy    0.824\n",
            "| epoch   2 |   500/ 1205 batches | accuracy    0.668\n",
            "| epoch   2 |  1000/ 1205 batches | accuracy    0.828\n",
            "| epoch   2 |  1000/ 1205 batches | accuracy    0.703\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   2 | time:  2.52s | valid accuracy    0.868,    0.643\n",
            "-----------------------------------------------------------\n",
            "| epoch   3 |   500/ 1205 batches | accuracy    0.845\n",
            "| epoch   3 |   500/ 1205 batches | accuracy    0.708\n",
            "| epoch   3 |  1000/ 1205 batches | accuracy    0.841\n",
            "| epoch   3 |  1000/ 1205 batches | accuracy    0.736\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   3 | time:  2.43s | valid accuracy    0.868,    0.644\n",
            "-----------------------------------------------------------\n",
            "| epoch   4 |   500/ 1205 batches | accuracy    0.858\n",
            "| epoch   4 |   500/ 1205 batches | accuracy    0.735\n",
            "| epoch   4 |  1000/ 1205 batches | accuracy    0.851\n",
            "| epoch   4 |  1000/ 1205 batches | accuracy    0.760\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   4 | time:  2.59s | valid accuracy    0.876,    0.642\n",
            "-----------------------------------------------------------\n",
            "| epoch   5 |   500/ 1205 batches | accuracy    0.864\n",
            "| epoch   5 |   500/ 1205 batches | accuracy    0.758\n",
            "| epoch   5 |  1000/ 1205 batches | accuracy    0.861\n",
            "| epoch   5 |  1000/ 1205 batches | accuracy    0.778\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   5 | time:  2.72s | valid accuracy    0.878,    0.641\n",
            "-----------------------------------------------------------\n",
            "| epoch   6 |   500/ 1205 batches | accuracy    0.869\n",
            "| epoch   6 |   500/ 1205 batches | accuracy    0.776\n",
            "| epoch   6 |  1000/ 1205 batches | accuracy    0.870\n",
            "| epoch   6 |  1000/ 1205 batches | accuracy    0.798\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   6 | time:  2.48s | valid accuracy    0.879,    0.633\n",
            "-----------------------------------------------------------\n",
            "| epoch   7 |   500/ 1205 batches | accuracy    0.874\n",
            "| epoch   7 |   500/ 1205 batches | accuracy    0.788\n",
            "| epoch   7 |  1000/ 1205 batches | accuracy    0.877\n",
            "| epoch   7 |  1000/ 1205 batches | accuracy    0.809\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   7 | time:  2.42s | valid accuracy    0.883,    0.631\n",
            "-----------------------------------------------------------\n",
            "| epoch   8 |   500/ 1205 batches | accuracy    0.877\n",
            "| epoch   8 |   500/ 1205 batches | accuracy    0.801\n",
            "| epoch   8 |  1000/ 1205 batches | accuracy    0.882\n",
            "| epoch   8 |  1000/ 1205 batches | accuracy    0.820\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   8 | time:  2.49s | valid accuracy    0.877,    0.625\n",
            "-----------------------------------------------------------\n",
            "| epoch   9 |   500/ 1205 batches | accuracy    0.883\n",
            "| epoch   9 |   500/ 1205 batches | accuracy    0.822\n",
            "| epoch   9 |  1000/ 1205 batches | accuracy    0.903\n",
            "| epoch   9 |  1000/ 1205 batches | accuracy    0.866\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   9 | time:  2.77s | valid accuracy    0.888,    0.670\n",
            "-----------------------------------------------------------\n",
            "| epoch  10 |   500/ 1205 batches | accuracy    0.898\n",
            "| epoch  10 |   500/ 1205 batches | accuracy    0.841\n",
            "| epoch  10 |  1000/ 1205 batches | accuracy    0.907\n",
            "| epoch  10 |  1000/ 1205 batches | accuracy    0.876\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  10 | time:  2.59s | valid accuracy    0.886,    0.676\n",
            "-----------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_mul(test_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RDy6CD8PfYF",
        "outputId": "9dc5ceb9-7f1d-4389-aa75-396dcea891df"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8412994772218073, 0.7135922330097088)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## #TODO 6: report the result in each set-up "
      ],
      "metadata": {
        "id": "R3UNrA_yPXrG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Single Task learning**\n",
        "\n",
        "Action classification : \n",
        "Acc = 0.8450336071695295, f1 = \n",
        "\n",
        "Object classification : \n",
        "Acc = 0.8454070201643017, f1 = \n",
        "\n",
        "**Multi-task learning**\n",
        "\n",
        "Action classification : \n",
        "Acc = 0.8412994772218073, f1 = \n",
        "\n",
        "Object classification : \n",
        "Acc = 0.7135922330097088, f1 = "
      ],
      "metadata": {
        "id": "dxJqwOZxNYwT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TODO 7: Use pretraining word embedding & handling out of vocabulary words\n",
        "\n",
        "Pretrained word embeddings can be used to improve the performance of a classification model, as they provide the model better representation of the words. These embeddings can be used to initialize the weights of the neural network model, providing it with a more meaningful starting point for learning especially on smaller datasets.\n",
        "\n",
        "In this part, we will try to use pretrained word embedding to initialize the word embeddings in this corpus.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "In the previous labs, we have always been using a vector of zeros to initialize words for OOVs. However, that is usually not the best method. In this part of the homework, you will try to handle these OOVs better.\n",
        "\n",
        "**Note :** you can use any pretrained word embedding.\n",
        "\n",
        "Repeat the model in TODO 5 with pretrained word embedding. Use a better initialization than a vector of zeroes.\n",
        "\n",
        "Here are some ideas:\n",
        "\n",
        "1.   [average](https://nlp.stanford.edu/~johnhew/vocab-expansion.html)\n",
        "2.   [Using character n-grams from FastText](https://fasttext.cc/docs/en/unsupervised-tutorial.html)\n",
        "3.   [Use a character LSTM model](https://link.springer.com/chapter/10.1007/978-3-030-18305-9_60)"
      ],
      "metadata": {
        "id": "iuAB51Q_AYnR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/PyThaiNLP/pythainlp-corpus/releases/download/thai2fit_wv-v0.1/thai2vec.bin -O thai2vec.bin"
      ],
      "metadata": {
        "id": "UjdZWFInQBF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## TODO 7.1: pretrained word embedding \n",
        "import gensim\n",
        "vec = gensim.models.KeyedVectors.load_word2vec_format(\"thai2vec.bin\", binary=True)\n",
        "itos = {i:k for i,(k,v) in enumerate(vec.vocab.items())}\n",
        "weight = vec.vectors\n",
        "stoi = {v:k for k,v in itos.items()}\n",
        "model_mul = Model(len(stoi), 300, num_class_act,num_class_obj).to(device)\n",
        "with torch.no_grad():\n",
        "    model_mul.embedding.weight.copy_(torch.tensor(weight))"
      ],
      "metadata": {
        "id": "Cfl0QwGSA1GC"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## TODO 7.2: how to handle out of vocab  \n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model_mul.parameters(), lr=LR)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
        "total_accu_act = None\n",
        "total_accu_obj = None\n",
        "num_train = int(len(data_act) * 0.95)\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    train_mul(train_dataloader)\n",
        "    accu_val_act, accu_val_obj= evaluate_mul(val_dataloader)\n",
        "    if total_accu_act is not None and total_accu_obj is not None and total_accu_act > accu_val_act and total_accu_obj > accu_val_obj:\n",
        "      scheduler.step()\n",
        "    else:\n",
        "       total_accu_act = accu_val_act\n",
        "       total_accu_obj = accu_val_obj\n",
        "    print('-' * 59)\n",
        "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
        "          'valid accuracy {:8.3f}, {:8.3f}'.format(epoch,\n",
        "                                           time.time() - epoch_start_time,\n",
        "                                           accu_val_act,accu_val_obj))\n",
        "    print('-' * 59)"
      ],
      "metadata": {
        "id": "7u5ivl7NCJ3X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b778b69d-ec0f-4c2f-80f5-c8f68283e9b0"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   500/ 1205 batches | accuracy    0.761\n",
            "| epoch   1 |   500/ 1205 batches | accuracy    0.521\n",
            "| epoch   1 |  1000/ 1205 batches | accuracy    0.804\n",
            "| epoch   1 |  1000/ 1205 batches | accuracy    0.643\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   1 | time:  2.52s | valid accuracy    0.868,    0.618\n",
            "-----------------------------------------------------------\n",
            "| epoch   2 |   500/ 1205 batches | accuracy    0.827\n",
            "| epoch   2 |   500/ 1205 batches | accuracy    0.686\n",
            "| epoch   2 |  1000/ 1205 batches | accuracy    0.829\n",
            "| epoch   2 |  1000/ 1205 batches | accuracy    0.719\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   2 | time:  2.45s | valid accuracy    0.869,    0.641\n",
            "-----------------------------------------------------------\n",
            "| epoch   3 |   500/ 1205 batches | accuracy    0.845\n",
            "| epoch   3 |   500/ 1205 batches | accuracy    0.725\n",
            "| epoch   3 |  1000/ 1205 batches | accuracy    0.847\n",
            "| epoch   3 |  1000/ 1205 batches | accuracy    0.750\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   3 | time:  2.49s | valid accuracy    0.876,    0.642\n",
            "-----------------------------------------------------------\n",
            "| epoch   4 |   500/ 1205 batches | accuracy    0.860\n",
            "| epoch   4 |   500/ 1205 batches | accuracy    0.750\n",
            "| epoch   4 |  1000/ 1205 batches | accuracy    0.855\n",
            "| epoch   4 |  1000/ 1205 batches | accuracy    0.772\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   4 | time:  2.45s | valid accuracy    0.882,    0.642\n",
            "-----------------------------------------------------------\n",
            "| epoch   5 |   500/ 1205 batches | accuracy    0.865\n",
            "| epoch   5 |   500/ 1205 batches | accuracy    0.766\n",
            "| epoch   5 |  1000/ 1205 batches | accuracy    0.865\n",
            "| epoch   5 |  1000/ 1205 batches | accuracy    0.786\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   5 | time:  2.99s | valid accuracy    0.882,    0.638\n",
            "-----------------------------------------------------------\n",
            "| epoch   6 |   500/ 1205 batches | accuracy    0.874\n",
            "| epoch   6 |   500/ 1205 batches | accuracy    0.803\n",
            "| epoch   6 |  1000/ 1205 batches | accuracy    0.891\n",
            "| epoch   6 |  1000/ 1205 batches | accuracy    0.847\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   6 | time:  2.55s | valid accuracy    0.890,    0.676\n",
            "-----------------------------------------------------------\n",
            "| epoch   7 |   500/ 1205 batches | accuracy    0.885\n",
            "| epoch   7 |   500/ 1205 batches | accuracy    0.822\n",
            "| epoch   7 |  1000/ 1205 batches | accuracy    0.901\n",
            "| epoch   7 |  1000/ 1205 batches | accuracy    0.863\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   7 | time:  2.52s | valid accuracy    0.893,    0.677\n",
            "-----------------------------------------------------------\n",
            "| epoch   8 |   500/ 1205 batches | accuracy    0.894\n",
            "| epoch   8 |   500/ 1205 batches | accuracy    0.834\n",
            "| epoch   8 |  1000/ 1205 batches | accuracy    0.904\n",
            "| epoch   8 |  1000/ 1205 batches | accuracy    0.866\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   8 | time:  2.49s | valid accuracy    0.891,    0.681\n",
            "-----------------------------------------------------------\n",
            "| epoch   9 |   500/ 1205 batches | accuracy    0.898\n",
            "| epoch   9 |   500/ 1205 batches | accuracy    0.841\n",
            "| epoch   9 |  1000/ 1205 batches | accuracy    0.908\n",
            "| epoch   9 |  1000/ 1205 batches | accuracy    0.869\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   9 | time:  2.66s | valid accuracy    0.892,    0.686\n",
            "-----------------------------------------------------------\n",
            "| epoch  10 |   500/ 1205 batches | accuracy    0.899\n",
            "| epoch  10 |   500/ 1205 batches | accuracy    0.844\n",
            "| epoch  10 |  1000/ 1205 batches | accuracy    0.909\n",
            "| epoch  10 |  1000/ 1205 batches | accuracy    0.872\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  10 | time:  3.09s | valid accuracy    0.892,    0.686\n",
            "-----------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Describe what pretrained word embedding you used, and how you handle OOVs.\n",
        "\n",
        "**ANS** TODO 7.3"
      ],
      "metadata": {
        "id": "fsglVix_LGyw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use thai2fit pre-trained word embedding model. It can handle OOV, which are words that do not appear in the modle's vocabulary. This is because the model is trained too generalize from the words it has seen during training to similara words that it has not seen before. When an OOV word is encountered, the model can still produce a meaningful vector representation for it based on its character n-grams."
      ],
      "metadata": {
        "id": "r7E_eyDrUtbD"
      }
    }
  ]
}